{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7345a9b7",
   "metadata": {},
   "source": [
    "# Hands-on RAG Exercise\n",
    "\n",
    "This notebook provides a step-by-step hands-on exercise for students to build their own RAG pipeline.\n",
    "\n",
    "## Objectives\n",
    "- Load and chunk a custom document\n",
    "- Build a FAISS index with embeddings\n",
    "- Query the index and return context\n",
    "- Generate answers using context + language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install needed packages\n",
    "%pip install faiss-cpu sentence-transformers openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bce829",
   "metadata": {},
   "source": [
    "## Step 1: Load Your Custom Text\n",
    "Paste or upload your own document below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7576e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_text = \"\"\"Paste your own text here about any topic (science, history, tech, etc.).\n",
    "Make sure it's at least a few paragraphs long for meaningful chunking.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0e17a",
   "metadata": {},
   "source": [
    "## Step 2: Chunk and Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Simple chunking\n",
    "chunks = [s.strip() for s in custom_text.split('.') if s]\n",
    "chunks = [c for c in chunks if len(c) > 20]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chunk_vectors = model.encode(chunks)\n",
    "\n",
    "index = faiss.IndexFlatL2(chunk_vectors.shape[1])\n",
    "index.add(np.array(chunk_vectors).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe66c30",
   "metadata": {},
   "source": [
    "## Step 3: Query Your Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Your question here\"\n",
    "query_vec = model.encode([query])\n",
    "\n",
    "D, I = index.search(np.array(query_vec).astype(\"float32\"), k=3)\n",
    "retrieved = [chunks[i] for i in I[0]]\n",
    "\n",
    "print(\"Retrieved Chunks:\")\n",
    "for r in retrieved:\n",
    "    print(\"-\", r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d1b5c",
   "metadata": {},
   "source": [
    "## Step 4: Answer Using Retrieved Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "context = \"\\n\".join(retrieved)\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"Answer:\", response['choices'][0]['text'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f689df9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "You've now:\n",
    "- Built a searchable knowledge base\n",
    "- Retrieved context with FAISS\n",
    "- Used OpenAI to generate an answer grounded in your document"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}