{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18359f00",
   "metadata": {},
   "source": [
    "# Vector Database Demo\n",
    "\n",
    "Created: 2025-05-21\n",
    "\n",
    "This notebook walks through the core concepts and a working demo of a vector database using `FAISS`.\n",
    "\n",
    "## Objectives\n",
    "- Understand what a vector database is\n",
    "- Create embeddings from sample text\n",
    "- Store embeddings in FAISS\n",
    "- Query FAISS for similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9337c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install faiss-cpu sentence-transformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79b6a2",
   "metadata": {},
   "source": [
    "## Step 1: Generate Embeddings from Text using Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd424ed",
   "metadata": {},
   "source": [
    "SentenceTransformer provides a simple API for converting sentences or texts into high-dimensional dense vectors (aka embeddings) that capture their semantic meaning.\n",
    "\n",
    "### Steps\n",
    "1. Tokenization\n",
    "    - \"The cat sat on the mat.\" → ['the', 'cat', 'sat', 'on', 'the', 'mat', '.']\n",
    "1. Each token is mapped to an ID (arbitrary integer) (from the model's vocabulary)\n",
    "    - ['the', 'cat', 'sat', 'on', 'the', 'mat', '.'] → [101, 4523, 3546, 1203, 101, 2981, 119]\n",
    "1. Embedding Layer (Word → Vector)\n",
    "    - Each token ID is looked up in a learned embedding table, which is just a matrix of floats.\n",
    "    - 101 might become:\n",
    "        - [0.01, 0.15, -0.23, ..., 0.07]  (384-dimensional vector)\n",
    "    - Each token ID is mapped to a dense (list or array where most or all values are non-zero) vector of floats — and these are learned during training.\n",
    "        - 'cat'  → [0.12, -0.8, 0.9, ...]\n",
    "        - 'dog'  → [0.11, -0.78, 0.91, ...]\n",
    "    - 'cat' and 'dog' have similar vectors — because they mean similar things.\n",
    "    - All tokens are now represented as vectors — these are initial word-level embeddings, but they don’t yet capture context or meaning beyond the word level.\n",
    "1. Transformer Layers\n",
    "    - Model applies attention mechanisms to process all tokens together, layer by layer.\n",
    "    - At each layer, each word’s vector is updated based on:\n",
    "        - What other words are nearby\n",
    "        - The relationships between words (e.g. subjects, objects, actions)\n",
    "        - Learned patterns from training on massive amounts of text\n",
    "    - After several layers (e.g. 6 in MiniLM), the vectors become contextualized:\n",
    "        - \"cat\" knows it’s the subject\n",
    "        - \"sat\" knows it’s a verb referring to the cat\n",
    "    - This is what gives the model its understanding of meaning.\n",
    "1. Pooling / Sentence Embedding\n",
    "    - Once each word has a contextual vector, you combine them into a single vector for the whole sentence.\n",
    "    - This could be done using:\n",
    "        - The vector for the [CLS] token\n",
    "            - Many transformer models (like BERT) add a special token [CLS] at the start of every input.\n",
    "        - Mean pooling (average of all token vectors)\n",
    "            - Take the average (mean) of all token embeddings (excluding special tokens like [PAD] or [SEP]).\n",
    "            - Gives equal weight to every word in the sentence.\n",
    "        - Max pooling\n",
    "            - For each dimension in the embedding vector, pick the maximum value across all token vectors.\n",
    "            - Think of it as capturing the most strongly activated (strongest signal) feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04026d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (5, 384)\n",
      "[[ 0.1302372  -0.01577281 -0.03671669 ...  0.05145749  0.0029666\n",
      "   0.05249826]\n",
      " [ 0.06359787 -0.05183902  0.02015788 ...  0.0532127   0.06901009\n",
      "   0.04439994]\n",
      " [ 0.09171666  0.04684387 -0.03066853 ...  0.00901199  0.01381297\n",
      "   0.07180584]\n",
      " [-0.04507284 -0.03677964  0.09603347 ...  0.07249691  0.01357245\n",
      "   0.05783718]\n",
      " [-0.04372275 -0.02872992 -0.0248621  ... -0.01439171 -0.09736661\n",
      "  -0.02572987]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2',device=\"cpu\")\n",
    "\n",
    "texts = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog played in the yard.\",\n",
    "    \"There is a cat under the table.\",\n",
    "    \"Dogs love playing fetch.\",\n",
    "    \"A man is sitting on a bench.\"\n",
    "]\n",
    "\n",
    "# Generate vector embeddings\n",
    "# Tokenizes each sentence.\n",
    "# Feeds them into the transformer.\n",
    "# Returns a dense vector (embedding) for each sentence.\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# 5 text inputs. \n",
    "# Each one is represented by a 384-dimensional vector.\n",
    "print(\"Shape of embeddings:\", embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0236155",
   "metadata": {},
   "source": [
    "## Step 2: Store Vectors in Facebook AI Similarity Search (FAISS) Index and Perform Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529780e",
   "metadata": {},
   "source": [
    "### The Problem: Search by Meaning, Not Words\n",
    "\n",
    "Imagine you want to build a system that can answer:\n",
    "- \"What produces energy in a cell?\"\n",
    "\n",
    "You have documents like:\n",
    "- \"The mitochondria is the powerhouse of the cell.\"\n",
    "- \"Photosynthesis occurs in plant cells.\"\n",
    "\n",
    "A keyword-based search engine (like traditional search) may not find \"mitochondria\" from \"energy\" if there's no overlap in words.\n",
    "\n",
    "We need to search by meaning, not exact wording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe3120",
   "metadata": {},
   "source": [
    "### The Solution: Store Vectors in FAISS\n",
    "\n",
    "Step-by-Step\n",
    "1. Convert documents to vectors\n",
    "    - Each sentence or paragraph is encoded into a dense vector (embedding) that captures its meaning.\n",
    "\n",
    "1. Store those vectors in FAISS\n",
    "    - FAISS is a fast vector index optimized for similarity search in high-dimensional space.\n",
    "\n",
    "1. Convert user queries to vectors\n",
    "    - The question \"What produces energy in a cell?\" is turned into a vector.\n",
    "\n",
    "1. Search FAISS for similar vectors\n",
    "    - FAISS compares your query vector to all stored vectors and returns the most similar ones — based on cosine similarity or L2 distance.\n",
    "\n",
    "1. Use the top results\n",
    "    - You can now return the top sentences, or pass them to a language model to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e64ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 5\n",
      "\n",
      "Top 3 most similar texts:\n",
      "- The dog played in the yard. (distance: 0.4290)\n",
      "- Dogs love playing fetch. (distance: 1.0269)\n",
      "- There is a cat under the table. (distance: 1.4182)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# FAISS needs to know how mnay dimenions each vector has.\n",
    "dimension = embeddings.shape[1]  # e.g. 384\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to index\n",
    "# FAISS requires exactly float32 (np.float32), \n",
    "# and many models (like Sentence Transformers) return float64 by default.\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "print(\"Number of vectors in the index:\", index.ntotal)\n",
    "\n",
    "# Query with a new sentence\n",
    "query = \"A dog is playing outside.\"\n",
    "query_vector = model.encode([query])\n",
    "# I → Indices\n",
    "# D → Distances (L2 same as Euclidean by default)\n",
    "D, I = index.search(np.array(query_vector).astype('float32'), k=3)\n",
    "\n",
    "print(\"\\nTop 3 most similar texts:\")\n",
    "for idx, dist in zip(I[0], D[0]):\n",
    "    print(f\"- {texts[idx]} (distance: {dist:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437716ae",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We used `sentence-transformers` to convert text into dense vectors.\n",
    "- Stored the vectors in a FAISS index.\n",
    "- Queried the index to find semantically similar text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
